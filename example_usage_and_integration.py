# -*- coding: utf-8 -*-
"""Example Usage and Integration.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1a-DaSwyTIVpHrugM4-3iD72lN-5X1nEi
"""

from carbon_calculator import CarbonFootprintCalculator, CarbonMetrics
from model_optimizer import SustainableModelOptimizer
from lifecycle_assessment import AILifecycleAssessment
import torch
import torch.nn as nn

def example_model_training():
    """Example training function for demonstration"""
    model = nn.Sequential(
        nn.Linear(784, 256),
        nn.ReLU(),
        nn.Linear(256, 128),
        nn.ReLU(),
        nn.Linear(128, 10)
    )

    # Simulate training
    optimizer = torch.optim.Adam(model.parameters())
    criterion = nn.CrossEntropyLoss()

    for epoch in range(5):  # Short training for demo
        dummy_input = torch.randn(32, 784)
        dummy_target = torch.randint(0, 10, (32,))

        optimizer.zero_grad()
        output = model(dummy_input)
        loss = criterion(output, dummy_target)
        loss.backward()
        optimizer.step()

    return model

def main():
    """Demonstrate the carbon-efficient AI framework"""

    # Initialize components
    carbon_calc = CarbonFootprintCalculator(region="finland")
    model_opt = SustainableModelOptimizer()
    lifecycle = AILifecycleAssessment()

    print("=== Carbon-Efficient AI Framework Demo ===\n")

    # 1. Measure training emissions
    print("1. Measuring training phase emissions...")
    training_metrics = carbon_calc.measure_training_emissions(
        example_model_training,
        model_size_mb=2.5
    )

    print(f"Training emissions: {training_metrics.total_emissions_kg:.4f} kg CO2")
    print(f"Energy consumed: {training_metrics.energy_consumed_kwh:.4f} kWh")
    print(f"Duration: {training_metrics.duration_hours:.4f} hours\n")

    # 2. Optimize model for sustainability
    print("2. Optimizing model for sustainability...")
    model = example_model_training()
    sample_input = torch.randn(1, 784)

    # Original model metrics
    original_metrics = model_opt.calculate_model_efficiency(model, sample_input)
    print(f"Original model size: {original_metrics['model_size_mb']:.2f} MB")

    # Apply optimizations
    pruned_model = model_opt.prune_model(model, sparsity_ratio=0.3)
    quantized_model = model_opt.quantize_model(pruned_model)

    optimized_metrics = model_opt.calculate_model_efficiency(quantized_model, sample_input)
    print(f"Optimized model size: {optimized_metrics['model_size_mb']:.2f} MB")
    print(f"Size reduction: {((original_metrics['model_size_mb'] - optimized_metrics['model_size_mb']) / original_metrics['model_size_mb']) * 100:.1f}%\n")

    # 3. Lifecycle assessment
    print("3. Generating lifecycle assessment...")

    dev_assessment = lifecycle.assess_development_phase(dev_hours=160, team_size=2)
    training_assessment = lifecycle.assess_training_phase(training_metrics)
    inference_assessment = lifecycle.assess_inference_phase(
        requests_per_day=10000,
        inference_energy_per_request=0.001,
        deployment_days=365
    )

    assessments = [dev_assessment, training_assessment, inference_assessment]
    report_df = lifecycle.generate_lifecycle_report(assessments)

    print("Lifecycle Assessment Report:")
    print(report_df.to_string(index=False))

    # 4. Generate visualization
    lifecycle.visualize_impact(report_df, save_path="ai_lifecycle_impact.png")

    print("\n=== Framework Demo Complete ===")
    print("Generated visualization saved as 'ai_lifecycle_impact.png'")

if __name__ == "__main__":
    main()